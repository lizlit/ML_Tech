{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiafRlQWFVWt",
        "outputId": "42306776-68a4-4d6a-91b1-f1ff2ba7577a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.Downloadong the text\n"
      ],
      "metadata": {
        "id": "CatATj3LOQ98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/11-0.txt', encoding='utf8').read()\n"
      ],
      "metadata": {
        "id": "nqrY41w1FWj4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Preproccessing"
      ],
      "metadata": {
        "id": "EcVU-9fKOU7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting to lower case and deleting end of strings\n",
        "f = f.replace('\\n', '').replace(\"’\", '').replace(\"“\", '').lower()\n"
      ],
      "metadata": {
        "id": "1EhntZiQFepK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split text into tokens\n",
        "tokens = pd.Series(word_tokenize(f))\n",
        "# deleting stopwords\n",
        "stop_words = stopwords.words(\"english\")\n",
        "tokens = tokens.loc[~tokens.isin(stop_words)]\n",
        "tokens = tokens.loc[~tokens.isin(list(string.punctuation + string.digits + \"’\"  + \"'\" + '\"' + '”' + '“' + '’' + '‘'))]"
      ],
      "metadata": {
        "id": "gECQS72FFmDc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tokens = tokens.apply(lambda w: lemmatizer.lemmatize(w))\n"
      ],
      "metadata": {
        "id": "fJFxGULjFxko"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grouping tokens in whole text into chapters and converting it to Dataframe\n",
        "chapters = []\n",
        "\n",
        "chapter_nmb = 0\n",
        "for word in tokens.iteritems():\n",
        "  if (word[1] == 'chapter'):\n",
        "    if chapter_nmb == 12:\n",
        "      chapter_nmb = 1\n",
        "    else:\n",
        "      chapter_nmb += 1\n",
        "  chapters.append({ 'chapter': chapter_nmb, 'word': word[1] })\n",
        "\n",
        "chapter_text = pd.DataFrame(chapters)"
      ],
      "metadata": {
        "id": "Smv3x1CVFzeG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Here we'r finding top-10 words in every chapter"
      ],
      "metadata": {
        "id": "oXwZlNZWOdXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def topWords(df, chapter):\n",
        "  current_chapter = df[df.chapter == chapter]\n",
        "  unique_words = current_chapter[current_chapter.word != 'alice'].word.unique()\n",
        "\n",
        "  words_count = []\n",
        "\n",
        "  for w in unique_words:\n",
        "    words_count.append({\n",
        "      'word': w,\n",
        "      'count': current_chapter.loc[current_chapter.word == w].word.count()\n",
        "    })\n",
        "  \n",
        "  counted = pd.DataFrame(words_count)\n",
        "  return counted.sort_values(by=['count'], ascending=False).head(10)\n",
        "\n",
        "for i in range(12):\n",
        "  i +=1\n",
        "  print('Top 10 words in chapter ' + str(i))\n",
        "  print(topWords(chapter_text, i))\n",
        "  print('----------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOctWvODF17h",
        "outputId": "05138ec0-d7bc-4791-bcbc-5fdba09b8763"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 words in chapter 1\n",
            "          word  count\n",
            "44        said    150\n",
            "315      queen     46\n",
            "121       went     30\n",
            "13      hatter     29\n",
            "15    dormouse     27\n",
            "1132      mock     25\n",
            "59        dont     23\n",
            "25        head     23\n",
            "32         one     21\n",
            "84        time     21\n",
            "----------------------\n",
            "Top 10 words in chapter 2\n",
            "          word  count\n",
            "27        said     40\n",
            "7         mock     26\n",
            "8       turtle     24\n",
            "28     gryphon     21\n",
            "512       soup     11\n",
            "190      would     11\n",
            "520  beautiful     10\n",
            "179       wont     10\n",
            "5      lobster     10\n",
            "66       dance      9\n",
            "----------------------\n",
            "Top 10 words in chapter 3\n",
            "         word  count\n",
            "80       said     36\n",
            "8        king     20\n",
            "218    hatter     16\n",
            "240  dormouse     10\n",
            "154       one      9\n",
            "68      court      9\n",
            "9       queen      9\n",
            "33     rabbit      8\n",
            "55    thought      8\n",
            "215   witness      8\n",
            "----------------------\n",
            "Top 10 words in chapter 4\n",
            "             word  count\n",
            "674       project     65\n",
            "112          work     64\n",
            "65           said     48\n",
            "762  gutenberg-tm     37\n",
            "704    foundation     22\n",
            "675     gutenberg     21\n",
            "721    electronic     21\n",
            "714          term     20\n",
            "702         state     18\n",
            "705          copy     17\n",
            "----------------------\n",
            "Top 10 words in chapter 5\n",
            "          word  count\n",
            "0      chapter      1\n",
            "1           v.      1\n",
            "2       advice      1\n",
            "3  caterpillar      1\n",
            "----------------------\n",
            "Top 10 words in chapter 6\n",
            "      word  count\n",
            "0  chapter      1\n",
            "1       vi      1\n",
            "2      pig      1\n",
            "3   pepper      1\n",
            "----------------------\n",
            "Top 10 words in chapter 7\n",
            "        word  count\n",
            "0    chapter      1\n",
            "1        vii      1\n",
            "2        mad      1\n",
            "3  tea-party      1\n",
            "----------------------\n",
            "Top 10 words in chapter 8\n",
            "             word  count\n",
            "0         chapter      1\n",
            "1            viii      1\n",
            "2           queen      1\n",
            "3  croquet-ground      1\n",
            "----------------------\n",
            "Top 10 words in chapter 9\n",
            "      word  count\n",
            "0  chapter      1\n",
            "1       ix      1\n",
            "2     mock      1\n",
            "3   turtle      1\n",
            "4    story      1\n",
            "----------------------\n",
            "Top 10 words in chapter 10\n",
            "        word  count\n",
            "0    chapter      1\n",
            "1         x.      1\n",
            "2    lobster      1\n",
            "3  quadrille      1\n",
            "----------------------\n",
            "Top 10 words in chapter 11\n",
            "      word  count\n",
            "0  chapter      1\n",
            "1       xi      1\n",
            "2    stole      1\n",
            "3     tart      1\n",
            "----------------------\n",
            "Top 10 words in chapter 12\n",
            "        word  count\n",
            "184     said    163\n",
            "256   little     69\n",
            "106     like     48\n",
            "145      one     45\n",
            "21   thought     39\n",
            "279    mouse     38\n",
            "198    thing     36\n",
            "94       see     36\n",
            "101     went     34\n",
            "280       im     33\n",
            "----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Here we are finding top-10 verbs in sent with Alce. We should split text not into chapters, but by symbols '.'"
      ],
      "metadata": {
        "id": "2zjppvMwOowA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = f.replace('”', '')\n",
        "sentences =  f.split('.')\n",
        "sentences_tokenized = [word_tokenize(sent) for sent in sentences]\n",
        "len(sentences_tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKVYCIS0F9LT",
        "outputId": "045a1fb2-1400-4964-de63-6142a0fc6e8d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1223"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alice_list = []\n",
        "k = 0\n",
        "for sent in sentences_tokenized:\n",
        "  k = 0\n",
        "  for word in sent:\n",
        "    if word =='alice':\n",
        "      k +=1\n",
        "  if k>0:\n",
        "    alice_list.append(sent)\n",
        "\n",
        "len(alice_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOny4GIwGH04",
        "outputId": "33096fcc-e20f-413c-c397-f926e4a3966f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "342"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filter = []\n",
        "for sent in alice_list:\n",
        "  sent = [token for token in sent if token not in stop_words]\n",
        "  sent = [lemmatizer.lemmatize(token, pos = 'v') for token in sent]\n",
        "  postag = nltk.pos_tag(sent)\n",
        "  for w in postag:\n",
        "    if (w[1] == 'VB') or (w[1] == 'VBP'):\n",
        "      filter.append(w[0])"
      ],
      "metadata": {
        "id": "MX9y6wiaHpD-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(filter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y78vIWK5HrWZ",
        "outputId": "7574597c-1550-4da6-c285-5c4393869dcf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['think', 'say', 'think', 'occur', 'wonder', 'seem', 'awatch', 'burn', 'run', 'see', 'alarge', 'go', 'consider', 'go', 'like', 'find', 'think', 'shallthink', 'brave', 'think', 'say', 'let', 'wouldbe', 'see', 'say', 'wonder', 'think', 'say', 'go', 'say', 'turn', 'hangingfrom', 'come', 'try', 'find', 'kneel', 'wander', 'cool', 'get', 'go', 'little', 'see', 'begin', 'think', 'find', 'find', 'say', 'say', 'wise', 'go', 'find', 'sort', 'say', 'shut', 'see', 'end', 'know', 'say', 'go', 'find', 'decide', 'get', 'find', 'find', 'reachit', 'see', 'try', 'try', 'use', 'say', 'advise', 'leave', 'generallygave', 'follow', 'bring', 'remember', 'try', 'pretend', 'think', 'pretend', 'leave', 'find', 'seem', 'get', 'manage', 'bekind', 'think', 'walk', 'go', 'see', 'ill', 'give', 'lie', 'tolook', 'get', 'say', 'say', 'go', 'go', 'tear', 'aboutfour', 'reach', 'begin', 'go', 'take', 'go', 'go', 'beenchanged', 'say', 'say', 'come', 'improve', 'seem', 'say', 'mabel', 'andi', 'go', 'learn', 'say', 'look', 'say', 'ill', 'stay', 'im', 'say', 'whileshe', 'say', 'find', 'run', 'think', 'say', 'come', 'goto', 'find', 'dig', 'rowof', 'say', 'find', 'use', 'think', 'think', 'know', 'rightway', 'do', 'remember', 'seem', 'wink', 'say', 'think', 'daresay', 'come', 'happen', 'feel', 'say', 'go', 'offend', 'talk', 'hear', 'say', 'go', 'throw', 'say', 'kill', 'go', 'make', 'go', 'dear', 'come', 'dont', 'turn', 'swim', 'think', 'say', 'let', 'get', 'ill', 'tell', 'get', 'seem', 'find', 'say', 'know', 'allowwithout', 'refuse', 'say', 'keep', 'catch', 'dear', 'turn', 'say', 'seem', '_is_', 'say', 'want', 'think', 'tospeak', 'seem', 'say', 'say', 'call', 'prize', 'get', 'go', 'turn', 'say', 'think', 'look', 'dare', 'think', 'say', 'take', 'look', 'know', 'say', 'add', 'say', 'look', 'call', 'keep', 'say', 'let', 'go', 'say', 'think', 'say', 'get', 'think', 'say', 'make', 'please', 'come', 'join', 'please', 'walk', 'know', 'say', 'begin', 'get', 'come', 'seem', 'see', 'send', 'go', 'lose', 'get', 'wonder', 'seem', 'go', '_are_', 'fetch', 'anda', 'run', 'explain', 'make', 'say', 'go', 'happen', 'get', 'see', 'go', 'theyd', 'let', 'stop', 'find', 'take', 'go', 'become', 'grow', 'get', 'wonder', 'think', 'think', '_never_', 'get', 'learn', 'shouldnt', 'know', 'shake', 'forget', 'say', 'wait', 'make', 'go', 'take', 'hear', 'make', 'think', 'want', 'make', 'otherladder', 'get', 'tie', 'dont', 'reach', 'dont', 'roof', '—mind', 'come', 'go', 'go', 'go', 'get', 'say', 'burn', 'say', 'think', 'iwonder', 'take', 'come', 'turn', 'cake', 'make', 'run', 'find', 'say', 'grow', 'find', 'say', 'try', 'frighten', 'think', 'eat', 'know', 'make', 'believe', 'keep', 'make', 'get', 'think', 'expect', 'run', 'run', 'make', 'run', 'till', 'say', 'fan', 'teach', 'forget', 'let', 'eat', 'drink', 'see', 'take', 'think', 'beenchanged', 'say', 'see', 'confuse', 'say', 'turn', 'know—and', 'think', 'say', 'feel', 'say', 'feel', 'make', 'say', 'tell', 'think', 'seem', 'turn', 'turn', 'say', 'shecould', 'wait', 'tell', 'puff', 'take', 'say', 'youthink', 'say', 'remember', 'iused—and', 'keep', 'remember', 'say', 'say', 'say', 'stand', 'injure', 'say', 'get', 'reply', 'know', 'say', 'say', 'remain', 'look', 'try', 'make', 'find', 'say', 'find', 'find', 'see', 'look', 'seem', 'leave', 'say', 'say', 'let', 'say', 'add', 'say', 'go', 'please', 'think', 'say', 'look-out', 'sleep', 'say', 'begin', 'mean', 'take', 'continue', 'raise', 'think', 'free', 'need', 'come', 'say', 'see', 'try', 'say', 'go', 'say', 'eat', 'egg', 'youknow', 'give', 'know', 'say', 'im', 'neck', 'keep', 'live', 'think', 'itll', 'frighten', 'run', 'go', 'knock', 'say', 'get', 'sense', 'go', 'door', 'look', 'think', 'get', 'ask', 'say', 'say', 'go', 'say', 'sneeze', 'tell', 'say', 'speak', 'say', 'say', 'take', 'go', 'know', 'grin', 'know', 'say', 'feel', 'think', 'introduce', '_not_', 'say', 'show', 'make', 'see', 'take', 'turn', 'say', 'cook', 'see', 'seem', 'go', 'twelve', 'dont', 'say', 'abidefigures', 'begin', 'give', 'shake', 'know', 'keep', 'hear', 'enjoy', 'nurse', 'say', 'hold', 'think', 'take', 'think', 'leave', 'say', 'leave', 'say', 'proper', 'see', 'doubt', 'get', 'didnot', 'go', 'say', 'ill', 'get', 'look', 'think', 'go', 'say', 'get', 'deny', 'try', 'want', 'go', 'know', 'say', 'think', 'go', 'say', 'say', 'say', 'say', 'get', 'happen', 'say', 'come', 'expect', 'walk', 'say', 'say', 'reply', 'keep', 'make', 'see', 'think', 'go', 'right', 'roof', 'think', '_plenty_', 'say', 'say', 'know', 'say', 'greatmany', 'make', 'say', 'fun', 'think', 'say', 'reply', 'know', 'monthis', 'say', 'turn', 'take', 'look', 'shake', 'hold', 'consider', 'say', 'itstays', 'puzzle', 'give', 'answer', 'say', 'know', 'say', 'say', 'say', 'know', 'go', 'say', 'finish', 'say', 'keep', 'suppose', 'say', 'happen', 'come', 'begin', 'know', 'say', 'elsie', 'live', 'say', 'take', 'do', 'know', 'ill', 'like', 'puzzle', 'go', 'live', 'take', 'say', 'offend', 'canttake', 'ask', 'say', 'say', 'tosome', 'go', 'please', 'go', 'say', 'learn', 'draw', 'say', 'take', 'begin', 'say', 'draw', 'treacle', 'say', 'let', 'dormouse', 'go', 'get', 'begin', 'say', 'go', 'wake', 'go', 'begin', 'know', 'muchness—did', 'see', 'say', 'say', 'bear', 'get', 'walk', 'take', 'call', 'try', 'go', 'say', 'think', 'come', 'say', 'look', 'go', 'say', 'myelbow', 'begin', 'stand', 'look', 'tell', 'say', 'look', 'see', 'say', 'wentby', 'lie', 'remember', 'use', 'think', 'lie', 'see', 'stand', 'come', 'stop', 'say', 'say', 'say', 'turn', 'go', 'name', 'please', 'say', 'add', 'know', 'say', 'say', 'remain', 'ranto', 'say', 'mean', 'happen', 'say', 'duchess', 'say', 'say', 'say', 'think', 'think', 'see', 'live', 'stand', 'make', 'find', 'succeed', 'get', 'tuck', 'get', 'straighten', 'go', 'helpbursting', 'get', 'find', 'ridge', 'get', 'begin', 'know', 'happen', 'become', 'leave', 'look', 'wonder', 'get', 'make', 'somebody', 'appear', 'begin', 'feel', 'think', 'play', 'begin', 'seem', 'thearch', 'go', 'run', 'say', 'say', 'extremely—', 'listen', 'go', 'win', 'say', 'go', 'say', 'say', 'look', 'get', 'look', 'say', 'go', 'see', 'hear', 'croquet', 'go', 'see', 'try', 'fly', 'catch', 'think', 'go', 'appear', 'find', 'make', 'say', 'think', 'say', 'find', 'make', 'hasnt', 'keep', 'say', 'make', 'go', 'say', 'do', 'everybody', 'mindingtheir', 'mean', 'say', 'take', 'take', 'find', 'think', 'try', 'bite', 'reply', 'feel', 'say', 'say', 'say', 'seem', 'agree', 'say', 'know', 'attend', 'say', 'follow', 'say', 'say', 'begin', 'tofeel', 'stand', 'let', 'go', 'say', 'say', 'leave', 'take', 'leave', 'end', 'leave', 'custodyand', 'leave', 'say', 'see', 'say', 'hear', 'say', 'say', 'tell', 'walk', 'say', 'go', 'see', 'leave', 'quite', 'go', 'say', 'say', 'say', 'think', 'go', 'go', 'hear', 'break', 'think', 'see', 'get', 'nothelp', 'think', 'come', 'sit', 'wasnt', 'teach', 'say', 'dull', 'ashamed', 'add', 'say', 'go', 'go', 'believe', 'say', 'hold', 'speak', 'go', 'say', 'soproud', 'learn', 'say', 'want', 'hear', 'say', 'know', 'suppose', 'say', 'ask', 'say', 'teach', 'drawl', 'say', 'say', 'think', 'make', 'go', 'try', 'minute', 'go', 'live', 'introduce', 'say', 'say', 'say', 'look', 'pretty', 'say', 'say', 'begin', 'wave', 'slowlyand', '—will', 'walk', 'say', 'say', 'feel', 'say', 'see', 'check', 'reply', 'say', 'call', 'think', 'say', 'consider', 'make', 'say', 'say', 'keep', 'want', 'say', 'go', 'say', 'say', 'come', 'go', 'say', 'say', 'begin', 'tell', 'think', 'make', 'think', 'say', '_ever_', 'happen', 'say', 'comewrong', 'go', 'continue', 'take', 'owl', 'permit', 'receive', 'conclude', 'go', 'think', 'leave', 'say', 'take', 'carry', 'make', 'do', 'think', 'seem', 'begin', 'pass', 'find', 'jury-box', 'think', 'say', 'see', 'suppose', 'look', 'make', 'see', 'look', 'write', 'make', 'know', 'ask', 'begin', 'think', 'get', 'decide', 'remain', 'say', 'say', 'do', 'think', 'get', 'make', 'see', 'like', 'get', 'say', 'forget', 'head', 'remind', 'say', 'look', 'say', 'know', 'say', 'say', 'say', 'see', 'think', 'look', 'say', 'go', 'say', 'aregular', 'say', 'weve', 'say', 'jury—if', 'say', 'grow', 'ill', 'say', 'go', 'know', 'give', 'give', 'hedid', 'go', 'say', 'say', 'say', 'say', 'grow', 'say', 'say', 'tell', 'remember', 'read', 'say', 'run', 'get', 'run', 'think', 'leave', 'think', 'till', 'begin', 'hear', 'andsee', 'keep', 'get', 'dream']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_verbs = []\n",
        "for w in filter:\n",
        "  counter = 1\n",
        "  for v in filter:\n",
        "    if w == v:\n",
        "      counter +=1\n",
        "      filter.remove(v)\n",
        "  top_verbs.append((w, counter))"
      ],
      "metadata": {
        "id": "LVnpIkhZJAxr"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(top_verbs, key=lambda v: -v[1])[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNOSjz4xNhjM",
        "outputId": "aeaf28b2-8ec6-4818-91ea-a87be858854e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('say', 176),\n",
              " ('go', 71),\n",
              " ('think', 60),\n",
              " ('get', 38),\n",
              " ('see', 31),\n",
              " ('say', 31),\n",
              " ('know', 27),\n",
              " ('make', 27),\n",
              " ('find', 23),\n",
              " ('take', 21)]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}